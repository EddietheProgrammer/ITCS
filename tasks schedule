Collect and Preprocess Data: (Kai 12/2)
Gather datasets (e.g., FakeNewsNet, LIAR).
Clean and tokenize text, extract features using TF-IDF, word embeddings, or transformers (e.g., BERT).

Model Selection:
(_ and _ 12/5)
Traditional: Logit, NB

(Rivas and Butters 12/5)
Deep Learning: LSTMs, Transformers (BERT, RoBERTa).

Train, Validate, Evaluate: (_ and _ 12/7)
Split data into training, validation, and test sets.
Evaluate using metrics like accuracy, F1-score, and ROC-AUC.
(Suggest branching out to SHAP values to help gain further understanding of the variables/words that are key to determine the difference between classes)

Storytelling, Conclusion, and Impact: (_ and _ 12/10)
Visualize findings using dashboards (e.g., graphs of detection rates, examples of fake vs. real content).
Summarize key insights and showcase how the system identifies patterns in fake news.
